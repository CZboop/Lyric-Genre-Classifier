{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClassifierLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EVnjCFTG5nqe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "n2mZx7PbD0Pf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2713a8d6-b9d0-4c24-d2ac-94ac70126090"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "lGlqtAvfD2XC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lyric_df = pd.read_csv('trainclean.csv',  usecols=range(0,5), header = 0, delimiter=\",\", quoting=csv.QUOTE_NONE, \n",
        "                       encoding='utf-8')\n",
        "lyric_df.columns = ['artist', 'song', 'genre', 'lang', 'lyrics']"
      ],
      "metadata": {
        "id": "-GOrTqrm7cyv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multi class data prep\n",
        "# 'Rock', 'Metal', 'Pop', 'Indie', 'R&B', 'Folk', 'Electronic', 'Jazz' are the classes to target, and only the english language lyrics\n",
        "# as ided from runnin genres = [i for i in lyric_df['genre'].unique() if isinstance(i, str)]\n",
        "lyrics_metal = lyric_df.loc[(lyric_df['genre'] == 'Metal') & (lyric_df['lang'] == 'en')]\n",
        "lyrics_rb = lyric_df.loc[(lyric_df['genre'] == 'R&B') & (lyric_df['lang'] == 'en')]\n",
        "lyrics_rock = lyric_df.loc[(lyric_df['genre'] == 'Rock') & (lyric_df['lang'] == 'en')]\n",
        "lyrics_pop = lyric_df.loc[(lyric_df['genre'] == 'Pop') & (lyric_df['lang'] == 'en')]\n",
        "lyrics_indie = lyric_df.loc[(lyric_df['genre'] == 'Indie') & (lyric_df['lang'] == 'en')]\n",
        "lyrics_folk = lyric_df.loc[(lyric_df['genre'] == 'Folk') & (lyric_df['lang'] == 'en')]\n",
        "lyrics_elec = lyric_df.loc[(lyric_df['genre'] == 'Electronic') & (lyric_df['lang'] == 'en')]\n",
        "lyrics_jazz = lyric_df.loc[(lyric_df['genre'] == 'Jazz') & (lyric_df['lang'] == 'en')]\n",
        "\n",
        "lyric_df = pd.concat([lyrics_metal, lyrics_rb, lyrics_rock, lyrics_pop, lyrics_indie, lyrics_folk, lyrics_elec, lyrics_jazz])"
      ],
      "metadata": {
        "id": "A_YGfAuDVDsO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "IwQMHERBIGea"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_NB_WORDS = 5000\n",
        "MAX_SEQ_LEN = 250\n",
        "EMBEDDING_DIM = 100"
      ],
      "metadata": {
        "id": "PtXzR3PuHhp-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True) \n",
        "tokenizer.fit_on_texts(lyric_df['lyrics'].values) #filtered data made above\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "print(\"Unique tokens = \", len(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YYEeFq3PpFw",
        "outputId": "b7b2868a-8dd6-48b9-9efe-4efb9500b89d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens =  196618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making seqs more uniform, len at least\n",
        "X = tokenizer.texts_to_sequences(lyric_df['lyrics'].values)\n",
        "X = pad_sequences(X, maxlen = MAX_SEQ_LEN)\n",
        "print('Data shape = ', X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-YlwRXDQsCr",
        "outputId": "2d145397-b6e0-420b-e4ce-bbdc22a287d1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape =  (246065, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class labels to nums\n",
        "y = pd.get_dummies(lyric_df['genre']).values\n",
        "print(\"Label shape = \", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXkSkazJRgKz",
        "outputId": "8705590f-1eb9-4af5-dbb9-c484ab6ac23e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label shape =  (246065, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# train test split - may later combine train test files if doing it this way, to get more data and still be able to test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state = 42)"
      ],
      "metadata": {
        "id": "Vd9IM39xSDdQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lstm model\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(8, activation='softmax')) # replace dis num with final number of classes classifying between/in dataset used if this changes\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size, validation_split=0.5, \n",
        "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKLoTkfCSx8B",
        "outputId": "28e61a93-2bee-4521-e36c-8647e3fbecb9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "962/962 [==============================] - 829s 858ms/step - loss: 1.3456 - accuracy: 0.4803 - val_loss: 1.2801 - val_accuracy: 0.5248\n",
            "Epoch 2/10\n",
            "962/962 [==============================] - 827s 860ms/step - loss: 1.1847 - accuracy: 0.5777 - val_loss: 1.1682 - val_accuracy: 0.5800\n",
            "Epoch 3/10\n",
            "962/962 [==============================] - 826s 859ms/step - loss: 1.1240 - accuracy: 0.6003 - val_loss: 1.1373 - val_accuracy: 0.5976\n",
            "Epoch 4/10\n",
            "962/962 [==============================] - 817s 849ms/step - loss: 1.0567 - accuracy: 0.6290 - val_loss: 1.1229 - val_accuracy: 0.6074\n",
            "Epoch 5/10\n",
            "962/962 [==============================] - 822s 855ms/step - loss: 1.0131 - accuracy: 0.6463 - val_loss: 1.1177 - val_accuracy: 0.6142\n",
            "Epoch 6/10\n",
            "962/962 [==============================] - 825s 857ms/step - loss: 0.9723 - accuracy: 0.6622 - val_loss: 1.1192 - val_accuracy: 0.6129\n",
            "Epoch 7/10\n",
            "962/962 [==============================] - 821s 854ms/step - loss: 0.9370 - accuracy: 0.6761 - val_loss: 1.1335 - val_accuracy: 0.6137\n",
            "Epoch 8/10\n",
            "962/962 [==============================] - 825s 858ms/step - loss: 0.9036 - accuracy: 0.6884 - val_loss: 1.1624 - val_accuracy: 0.6086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving trained model and tokenizer\n",
        "import pickle\n",
        "from pickle import dump\n",
        "model.save('multigenre_model.h5')\n",
        "dump(tokenizer, open('multigenre_tokenizer.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "a7dzA3TCYhVN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing model accuracy\n",
        "accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Loss: \", accuracy[0])\n",
        "print(\"Accuracy: \", accuracy[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5H7swHreS9E",
        "outputId": "ac6d5a8e-c309-4430-9a08-b23477880719"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3845/3845 [==============================] - 290s 75ms/step - loss: 1.1617 - accuracy: 0.6083\n",
            "Loss:  1.1617070436477661\n",
            "Accuracy:  0.6082839369773865\n"
          ]
        }
      ]
    }
  ]
}