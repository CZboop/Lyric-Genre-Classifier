{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClassifierLSTMDataProcessed.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVnjCFTG5nqe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "n2mZx7PbD0Pf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61d37264-bf36-46d8-f5ec-02ca8deeec72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "lGlqtAvfD2XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lyric_df = pd.read_csv('trainclean.csv',  usecols=range(0,5), header = 0, delimiter=\",\", quoting=csv.QUOTE_NONE, \n",
        "                       encoding='utf-8')\n",
        "lyric_df.columns = ['artist', 'song', 'genre', 'lang', 'lyrics']"
      ],
      "metadata": {
        "id": "-GOrTqrm7cyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multi class data prep\n",
        "# 'Rock', 'Metal', 'Pop', 'Indie', 'R&B', 'Folk', 'Electronic', 'Jazz' are the classes to target, and only the english language lyrics\n",
        "# as ided from runnin genres = [i for i in lyric_df['genre'].unique() if isinstance(i, str)]\n",
        "lyrics_metal = lyric_df.loc[(lyric_df['genre'] == 'Metal') & (lyric_df['lang'] == 'en')]\n",
        "lyrics_rb = lyric_df.loc[(lyric_df['genre'] == 'R&B') & (lyric_df['lang'] == 'en')]\n",
        "lyrics_rock = lyric_df.loc[(lyric_df['genre'] == 'Rock') & (lyric_df['lang'] == 'en')]\n",
        "lyrics_pop = lyric_df.loc[(lyric_df['genre'] == 'Pop') & (lyric_df['lang'] == 'en')]\n",
        "lyrics_indie = lyric_df.loc[(lyric_df['genre'] == 'Indie') & (lyric_df['lang'] == 'en')]\n",
        "lyrics_folk = lyric_df.loc[(lyric_df['genre'] == 'Folk') & (lyric_df['lang'] == 'en')]\n",
        "lyrics_elec = lyric_df.loc[(lyric_df['genre'] == 'Electronic') & (lyric_df['lang'] == 'en')]\n",
        "lyrics_jazz = lyric_df.loc[(lyric_df['genre'] == 'Jazz') & (lyric_df['lang'] == 'en')]\n",
        "\n",
        "lyric_df = pd.concat([lyrics_metal, lyrics_rb, lyrics_rock, lyrics_pop, lyrics_indie, lyrics_folk, lyrics_elec, lyrics_jazz])"
      ],
      "metadata": {
        "id": "A_YGfAuDVDsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# basically want to remove stopwords and save again as a new csv, then use that\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "lyric_df['lyrics'] = lyric_df['lyrics'].apply(lambda x: ' '.join([word for word in x.lower().split() if word not in (stop_words)]))"
      ],
      "metadata": {
        "id": "efl-xlQ7ZFt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('lyric_data_nostopwords_lower.csv', 'a', newline='') as file:\n",
        "      lyric_df.to_csv(file)"
      ],
      "metadata": {
        "id": "dU2rHfUQtJEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lyric_df.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExFmtxN_tyNK",
        "outputId": "03514844-c256-487a-8078-e48d30eee1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                        artist  ...                                             lyrics\n",
              "100              3 doors down  ...  A hundred days made older Since last time I sa...\n",
              "101              3 doors down  ...  There's another world inside may never see The...\n",
              "102              3 doors down  ...  I took walk around world To ease troubled mind...\n",
              "103              3 doors down  ...  One kiss could best thing one lie could worst ...\n",
              "104              3 doors down  ...  He spends nights California Watching stars big...\n",
              "...                       ...  ...                                                ...\n",
              "291031          george benson  ...  Strollin' park watching winter turn spring Wal...\n",
              "291035          alexa lusader  ...  Oooooo Fly high Just let fly kite starry night...\n",
              "291050                 g love  ...  This song coffee Y'all like Coffee? I like Hm ...\n",
              "291095      delbert mcclinton  ...  I learned swim daddy threw river The army taug...\n",
              "291099  cherry poppin daddies  ...  Honor word To knights old pledged faith In lov...\n",
              "\n",
              "[246065 rows x 5 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "IwQMHERBIGea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_NB_WORDS = 5000\n",
        "MAX_SEQ_LEN = 250\n",
        "EMBEDDING_DIM = 100"
      ],
      "metadata": {
        "id": "PtXzR3PuHhp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True) \n",
        "tokenizer.fit_on_texts(lyric_df['lyrics'].values) #filtered data made above\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "print(\"Unique tokens = \", len(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YYEeFq3PpFw",
        "outputId": "028ad7f5-a49a-422a-9ba6-1d5294c8e2f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens =  196223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making seqs more uniform, len at least\n",
        "X = tokenizer.texts_to_sequences(lyric_df['lyrics'].values)\n",
        "X = pad_sequences(X, maxlen = MAX_SEQ_LEN)\n",
        "print('Data shape = ', X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-YlwRXDQsCr",
        "outputId": "1831af81-4aae-437a-ed19-a3a6007794ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape =  (246065, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class labels to nums\n",
        "y = pd.get_dummies(lyric_df['genre']).values\n",
        "print(\"Label shape = \", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXkSkazJRgKz",
        "outputId": "739bb2fb-9deb-4f5f-bce3-3e1fd6305d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label shape =  (246065, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# train test split - may later combine train test files if doing it this way, to get more data and still be able to test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "Vd9IM39xSDdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lstm model\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(8, activation='softmax')) # replace this num with final number of classes classifying between/in dataset used if this changes\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 64\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size, validation_split=0.5, \n",
        "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKLoTkfCSx8B",
        "outputId": "13934362-e0ce-4e98-c7d4-b18281fce371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1538/1538 [==============================] - 1137s 738ms/step - loss: 1.2318 - accuracy: 0.5543 - val_loss: 1.1364 - val_accuracy: 0.6039\n",
            "Epoch 2/5\n",
            "1538/1538 [==============================] - 1128s 734ms/step - loss: 1.0870 - accuracy: 0.6208 - val_loss: 1.0870 - val_accuracy: 0.6191\n",
            "Epoch 3/5\n",
            "1538/1538 [==============================] - 1132s 736ms/step - loss: 1.0313 - accuracy: 0.6423 - val_loss: 1.0755 - val_accuracy: 0.6243\n",
            "Epoch 4/5\n",
            "1538/1538 [==============================] - 1140s 741ms/step - loss: 0.9879 - accuracy: 0.6560 - val_loss: 1.0838 - val_accuracy: 0.6113\n",
            "Epoch 5/5\n",
            "1538/1538 [==============================] - 1161s 755ms/step - loss: 0.9492 - accuracy: 0.6685 - val_loss: 1.0721 - val_accuracy: 0.6290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving trained model and tokenizer\n",
        "import pickle\n",
        "from pickle import dump\n",
        "model.save('multigenre_model_nostopwords.h5')\n",
        "dump(tokenizer, open('multigenre_tokenizer_nostopwords.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "a7dzA3TCYhVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing model accuracy\n",
        "accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Loss: \", accuracy[0])\n",
        "print(\"Accuracy: \", accuracy[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5H7swHreS9E",
        "outputId": "d1cd972e-c261-47ed-8c21-69ddfd394835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1538/1538 [==============================] - 103s 67ms/step - loss: 1.0756 - accuracy: 0.6258\n",
            "Loss:  1.075553059577942\n",
            "Accuracy:  0.6258102655410767\n"
          ]
        }
      ]
    }
  ]
}