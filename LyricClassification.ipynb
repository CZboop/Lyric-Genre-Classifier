{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EVnjCFTG5nqe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lenc = LabelEncoder()"
      ],
      "metadata": {
        "id": "IL25DsXt7kh9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lyric_df = pd.read_csv('lyrics-data.csv',  usecols=[0,1,2,4], header = None, delimiter=\",\", quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
        "lyric_df.columns = ['alink', 'song', 'lyric', 'lang']\n",
        "# for both, data has commas inside which is messing with delimiter, come back to this"
      ],
      "metadata": {
        "id": "-GOrTqrm7cyv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lyric_df.shape"
      ],
      "metadata": {
        "id": "URpfBAMN8VjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artist_df = pd.read_csv('artists-data.csv', usecols=[0,1,3,4,5],header = None, delimiter=\",\", quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
        "artist_df.columns = ['artist', 'songs', 'link', 'genre', 'genres']"
      ],
      "metadata": {
        "id": "FkjpIhu0BJYe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artist_df.shape"
      ],
      "metadata": {
        "id": "bLHv5NX3BJgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artist_df.head\n",
        "lyric_df.head"
      ],
      "metadata": {
        "id": "ZHKwU_fvC5KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# just getting english lyrics and a temporary way of removing some of the dodgy data due to delimiter issue\n",
        "lyric_df = lyric_df.loc[lyric_df['lang'] == 'ENGLISH']\n",
        "\n",
        "# making a list of genres to match up with rows of df that can then add as a column\n",
        "lyrics_genres = []\n",
        "for index, row in lyric_df.iterrows():\n",
        "  # below may be returning a series, currently just string casting may want to handle other way later\n",
        "  main_genre = artist_df.loc[artist_df['link'] == row['alink']]['genre']\n",
        "  lyrics_genres.append(str(main_genre))\n",
        "\n",
        "# something not quite right getting multiple genres for some and none for others it seems\n",
        "\n",
        "# adding genres to lyrics\n",
        "lyric_df['genre'] = lyrics_genres\n"
      ],
      "metadata": {
        "id": "j_kPZNi8CEv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now that there's genre column will encode to use as class/ifier\n",
        "lyric_data_encoded = lyric_df.apply(lenc.fit_transform, axis=0)\n",
        "lyric_data_encoded1 = lyric_data_encoded.loc[lyric_data_encoded['genre'] == 0]\n",
        "lyric_data_encoded2 = lyric_data_encoded.loc[lyric_data_encoded['genre'] == 1]\n",
        "lyric_data_encoded = pd.concat([lyric_data_encoded1, lyric_data_encoded2])\n",
        "lyric_data_encoded.head\n",
        "# because of genre extraction issues, there are more genres appearing than there should be, may filter out non standard, ignore etc "
      ],
      "metadata": {
        "id": "I_mUsWKMXRXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_lyric_data = lyric_data_encoded.values"
      ],
      "metadata": {
        "id": "Pce3AyTYcJS1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assigning lyrics and genre to info and class for later use\n",
        "lyric_info = encoded_lyric_data[:, :-1]\n",
        "lyric_classes = encoded_lyric_data[:, -1]"
      ],
      "metadata": {
        "id": "jSZmRkVccP8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,  X_test, y_train, y_test = train_test_split(\n",
        "    lyric_info, lyric_classes, test_size=0.40, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "zHv-QS0efu2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prior_prob(y, label):\n",
        "  total = y.shape[0]\n",
        "  actual = np.sum(y == label)\n",
        "\n",
        "  return total / actual\n"
      ],
      "metadata": {
        "id": "w4DQl4wsgn9o"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conditional_prob(X_train, y_train, feature_col, feature_val, label):\n",
        "  X_filtered = X_train[y_train == label]\n",
        "  num = np.sum(X_filtered[:, feature_col] == feature_val)\n",
        "  denom = X_filtered.shape[0]\n",
        "\n",
        "  return num/denom\n"
      ],
      "metadata": {
        "id": "c-l0_d6Oh2Nz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X_train, y_train, X_test):\n",
        "  classes = np.unique(y_train)\n",
        "  features = X_train.shape[1]\n",
        "  \n",
        "  posterior_prob = []\n",
        "\n",
        "  for label in classes:\n",
        "    chance = 1.0\n",
        "    for feature in range(features):\n",
        "      cond = conditional_prob(X_train, y_train, feature, X_test[feature], label)\n",
        "      chance = chance * cond \n",
        "    prior = get_prior_prob(y_train, label)\n",
        "    posterior = chance * prior\n",
        "    posterior_prob.append(posterior)\n",
        "\n",
        "    most_likely = np.argmax(posterior_prob)\n",
        "\n",
        "    return most_likely"
      ],
      "metadata": {
        "id": "KFfdpqykjXvV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(X_train, y_train, X_test, y_test):\n",
        "  preds = []\n",
        "  for i in range (X_test.shape[0]):\n",
        "    pred = predict(X_train, y_train, X_test[i])\n",
        "    preds.append(pred)\n",
        "  class_preds = np.array(preds)\n",
        "  \n",
        "  accuracy = np.sum(class_preds == y_test)/ class_preds.shape[0]\n",
        "\n",
        "  return accuracy \n"
      ],
      "metadata": {
        "id": "oNOyK57ClggQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = get_accuracy(X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "58Gw34GRmyjx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc)"
      ],
      "metadata": {
        "id": "bZ2Pj6r31d2B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}